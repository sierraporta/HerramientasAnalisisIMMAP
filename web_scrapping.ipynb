{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Credits: https://jovian.ai/saini-9/research-papers-web-scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the liberary\n",
    "import requests\n",
    "from time import sleep \n",
    "import re\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define header to access google scholar website\n",
    "headers = {'user-agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.114 Safari/537.36'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function for the getting inforamtion of the web page\n",
    "def get_paperinfo(paper_url):\n",
    "    #download the page\n",
    "    response=requests.get(url,headers=headers)\n",
    "    # check successful response\n",
    "    if response.status_code != 200:\n",
    "        print('Status code:', response.status_code)\n",
    "        raise Exception('Failed to fetch web page ')\n",
    "    \n",
    "    #parse using beautiful soup\n",
    "    paper_doc = BeautifulSoup(response.text,'html.parser')\n",
    "\n",
    "    return paper_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function for the extracting information of the tags\n",
    "def get_tags(doc):\n",
    "    paper_tag = doc.select('[data-lid]')\n",
    "    cite_tag = doc.select('[title=Cite] + a')\n",
    "    link_tag = doc.find_all('h3',{\"class\" : \"gs_rt\"})\n",
    "    author_tag = doc.find_all(\"div\", {\"class\": \"gs_a\"})\n",
    "\n",
    "    return paper_tag,cite_tag,link_tag,author_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it will return the title of the paper\n",
    "def get_papertitle(paper_tag):\n",
    "    paper_names = []\n",
    "  \n",
    "    for tag in paper_tag:\n",
    "        paper_names.append(tag.select('h3')[0].get_text())\n",
    "\n",
    "    return paper_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it will return the number of citation of the paper\n",
    "def get_citecount(cite_tag):\n",
    "    cite_count = []\n",
    "    for i in cite_tag:\n",
    "        cite = i.text\n",
    "        if i is None or cite is None:  # if paper has no citatation then consider 0\n",
    "            cite_count.append(0)\n",
    "        else:\n",
    "            tmp = re.search(r'\\d+', cite) # its handle the None type object error and re use to remove the string \" cited by \" and return only integer value\n",
    "            if tmp is None :\n",
    "                cite_count.append(0)\n",
    "            else :\n",
    "                cite_count.append(int(tmp.group()))\n",
    "\n",
    "    return cite_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for the getting link information\n",
    "def get_link(link_tag):\n",
    "    links = []\n",
    "    for i in range(len(link_tag)) :\n",
    "        links.append(link_tag[i].a['href']) \n",
    "\n",
    "    return links "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for the getting autho , year and publication information\n",
    "def get_author_year_publi_info(authors_tag):\n",
    "    years = []\n",
    "    publication = []\n",
    "    authors = []\n",
    "    for i in range(len(authors_tag)):\n",
    "        authortag_text = (authors_tag[i].text).split()\n",
    "        year = int(re.search(r'\\d+', authors_tag[i].text).group())\n",
    "        years.append(year)\n",
    "        publication.append(authortag_text[-1])\n",
    "        author = authortag_text[0] + ' ' + re.sub(',','', authortag_text[1])\n",
    "        authors.append(author)\n",
    "  \n",
    "    return years , publication, authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating final repository\n",
    "paper_repos_dict = {\n",
    "                    'Paper Title' : [],\n",
    "                    'Year' : [],\n",
    "                    'Author' : [],\n",
    "                    'Citation' : [],\n",
    "                    'Publication' : [],\n",
    "                    'Url of paper' : [] }\n",
    "\n",
    "# adding information in repository\n",
    "def add_in_paper_repo(papername,year,author,cite,publi,link):\n",
    "    paper_repos_dict['Paper Title'].extend(papername)\n",
    "    paper_repos_dict['Year'].extend(year)\n",
    "    paper_repos_dict['Author'].extend(author)\n",
    "    paper_repos_dict['Citation'].extend(cite)\n",
    "    paper_repos_dict['Publication'].extend(publi)\n",
    "    paper_repos_dict['Url of paper'].extend(link)\n",
    "\n",
    "    return pd.DataFrame(paper_repos_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,110,10):\n",
    "    print(i)\n",
    "    # get url for the each page\n",
    "    url = \"https://scholar.google.com/scholar?start={}&q=object+detection+in+aerial+image+&hl=en&as_sdt=0,5\".format(i)\n",
    "    #url = \"https://scholar.google.com/scholar?start={}&q=mercado+laboral+en+colombia+&hl=en&as_sdt=0,5\".format(i)\n",
    "    #url = \"https://scholar.google.com/scholar?start={}&q=mercado+laboral+en+Colombia&hl=en&as_sdt=0%2C5&as_ylo=2011&as_yhi=\"# \"https://scholar.google.com/scholar?start={}&q=mercado+laboral+Colombia&hl=en&as_sdt=0%2C5&as_ylo=2011&as_yhi=\".format(i)\n",
    "    # function for the get content of each page\n",
    "    doc = get_paperinfo(url)\n",
    "\n",
    "    # function for the collecting tags\n",
    "    paper_tag,cite_tag,link_tag,author_tag = get_tags(doc)\n",
    "  \n",
    "    # paper title from each page\n",
    "    papername = get_papertitle(paper_tag)\n",
    "\n",
    "    # year , author , publication of the paper\n",
    "    year , publication , author = get_author_year_publi_info(author_tag)\n",
    "\n",
    "    # cite count of the paper \n",
    "    cite = get_citecount(cite_tag)\n",
    "\n",
    "    # url of the paper\n",
    "    link = get_link(link_tag)\n",
    "\n",
    "    # add in paper repo dict\n",
    "    final = add_in_paper_repo(papername,year,author,cite,publication,link)\n",
    "  \n",
    "    # use sleep to avoid status code 429\n",
    "    sleep(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final.to_csv('mercado_laboral_Colombia_scholar2.csv', sep=',', index=False,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
